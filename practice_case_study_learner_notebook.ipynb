{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2abe9e-d390-40eb-8efe-641580015163",
   "metadata": {},
   "source": [
    "# Practice Case Study\n",
    "## German Credit Risk Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb1bae-bfd5-417e-89ec-c7afaccb362f",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "The approval of loans to customers is the most important aspect of a bank, yet it is also a time-consumed process. Value Trust Bank was founded in 2003 in Germany with the objective of providing loans and finance to individuals and enterprises. After three years of launch, the bank was experiencing difficulties in making profits and dealing with customers who do not repay their loans back. Now, the bank manager wants a software application that will identify the right customers to approve the loan and it will also help to reduce the effort and time required to process the applications in order to increase the customer experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded3788-c671-4255-8b10-efc71d4eb771",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import all necessary libraries\n",
    "\n",
    "In this example, we will be using `pandas`, `numpy`, `datetime` and `time` libraries for processing our data, the `tarfile` library to package our trained model, the `boto3` and `sagemaker` libraries to interact with aws services & sagemaker (to start training & hyper-parameter jobs, and to deploy the model using endpoints) and finally a bunch of packages from the `sklearn` library for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa7a0f-5eb1-4de4-80ea-229818ba370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae59584-547d-47c8-b276-6e192c253f3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup a SageMaker Session\n",
    "\n",
    "In this step, we will setup a SageMaker session using the `boto3` library and set the region and S3 bucket we will be using for this walkthrough. I will be setting my S3 location to be the default bucket that was created for me by SageMaker, but you can change this if you want to by giving the URL of a different S3 bucket you might want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd300e-8bd4-4490-aa73-21f57631f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a sagemaker session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9987776-a63b-4742-a063-dd8bc9e7b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get region and defualt bucket\n",
    "\n",
    "\n",
    "# Display region and bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "609a3fe0-494e-4112-9f1b-99a7b1828a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables to write data into s3\n",
    "data = \"\"\n",
    "prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a64052-2e2d-4abc-9baa-a50e3077d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data into s3\n",
    "boto3.Session().resource('s3').Bucket(bucket) \\\n",
    "     .Object(os.path.join(prefix, 'input/german_credit_case_study.csv')) \\\n",
    "     .upload_file('german_credit_case_study.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5b917-d964-4da8-a97e-2090bf9e52dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read the data & pre-process\n",
    "In the case-study we are going to use 'german_credit.csv', Each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes.The attributes are:\n",
    "\n",
    "* _Age_  = customer age\n",
    "* _Sex_  = customer gender\n",
    "* _JOB_  = customer profession\n",
    "* _HOSUING_  = does customer has a house\n",
    "* _Savings account$Checking account_  = customer savings account and checking account\n",
    "* _Credit amount_  = customer credit amount \n",
    "* _Duration_  = duration of loan (months)\n",
    "* _Purpose_   = loan purpose\n",
    "* _risk_ = Class variable (1:person is at risk, 0: perosn is not risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6104bcf-d8cf-4a92-818f-92e69c065af0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Read data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da77fd4-814a-4697-a1ac-9b7d19ea6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from S3 into a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fce4cc0-97cc-43b8-b1f0-8d91824f979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097f67c-3453-416b-aaeb-518fc4193858",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e16574-5fa2-4854-8e0b-95820666e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a212d02-421a-4148-b046-b31886137ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in age column by imputing with median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3845d238-c90b-4128-a6f9-c17c62841177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in Sex column by imputing with mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36dc41-e6e9-497c-97f3-4da167f37d4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Manage Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "826283d9-591f-4234-8503-bca48bb30367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the vector feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c013321-9744-44c5-950e-b9d971e06a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply lamba function to split the vector into 2 parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b4c25-184f-4683-a119-ca801e157253",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Manage Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a43efc9-bc9c-4700-9ad3-6a1d5a840beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the vector column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc9c5e3-b421-466c-9fb3-9b3a19c8c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns 'Age' to 'age,'Sex' to 'sex','JOB' to 'job','HOUSING' to 'housing','Credit amount' to 'credit_amount','Duration' to 'duration','Purpose' to 'purpose'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb844db-79a5-4d30-9813-0c45dcdfea37",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "131f18ce-2875-4392-9c4e-02877a494b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for all duplicate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5df07da1-c40a-4533-936c-254af86ce0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows (If any)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95121ae-e1d4-4c47-8e25-4f24925aeb66",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Parse Features to the correct datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a58dc7e0-35a3-4231-b1e4-ca5b083048db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481df62-db98-447f-bf68-0bf3222ef71e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Format string (standardize string values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daa5dfc9-908d-412d-9b18-45c6e0c06718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values of job column feature \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e62df275-aa12-4efd-b2fa-183053c4ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RegEx to replace '-' with '' (No space)\n",
    "\n",
    "# Use RegEx to replace '_' to ' ' (Space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095c2139-ea09-4e9d-adb9-71e26b0beee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regex to replace \"?\" with frequant value of purpose column (Most frequant value Ex: Mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3816d1-f8e8-4b3a-a0bd-ac7e49e7cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string features in 'housing' column into lower case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f206c56-a54b-4569-b02f-dc79916a8ea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0c122-16bd-435a-abde-d40227107cfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd747b4-eecb-48ca-9f5b-6cdb2b2d31da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19c6f2a8-7ca6-4223-b725-8fdcc899efc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### How is age distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4b00b-b974-46c5-96fa-1378d378db36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3adda13c-3574-481a-8e54-e54fe8dd06cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa044a75-5117-4f94-8ed0-db940bdcb873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db380761-8f0e-47d8-8bbd-1cb3c5fe485b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Multicollinearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d2d72-173a-467c-b60d-293826423e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfe60c45-28c9-4756-889e-96011f0fde0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d9fd5-c451-4cc8-8862-a9664f2ec8e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Encode Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280eb5e0-ad85-464c-844b-d72627b72561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d97af7c-0e61-4ce9-aa00-79bd385f33ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data Imbalance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89736d-5b0a-4e1d-9828-6f907cf83fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47ac45d3-ca81-464c-ac4a-8b88e44196a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Process Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31221309-2247-4c2b-a8be-50c0454547e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data into new variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa5ff986-c421-43aa-ab1d-ad07607c808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the values of age, credit_amount, duraion column with the help of standard scaler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b5506-d815-48bf-ad27-74194cf8f757",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split data and upload back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82032098-28d7-4624-acdd-59b7413ef43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Train & Test dataframes\n",
    "\n",
    "# Write the train and test dataframes to sagemaker file browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "280c6553-510b-44df-a809-39260d4072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload train data to s3\n",
    "\n",
    "\n",
    "# Upload test data to s3\n",
    "\n",
    "\n",
    "# Display train and test data location in s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9616996-faff-4433-8300-0adb0c48b86d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build models to train using a Classification Algorithm\n",
    "\n",
    "In this step, we will first read the data from S3, split the features & target into train & test parts, and create and evaluate multiple classification models like:\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Tree Classifier\n",
    "* Random Forest Classifier\n",
    "* Gradient Boosting\n",
    "* Adaptive Boosting\n",
    "* K-Nearest Neighhour Classifier\n",
    "* Support Vector Machine Classifier\n",
    "* Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6b4b6-510b-4b72-9b82-bc951d9dba44",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Read train & test data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1d10b0c-4cfb-47a5-9a6e-71d61365941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training & testing datasets from s3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bef6e9c9-819b-4fea-af5f-6efb0435dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataframes with features & target\n",
    "\n",
    "# Create test dataframes with features & target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2d2bc-9102-4820-852b-3850477e0e5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train Classification Models using the data\n",
    "\n",
    "NOTE: _Uncomment the model you wish to use, keep the rest commented_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2ad4345-3ac9-43c1-8212-fc280f8547ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(random_state=1)\n",
    "# model = DecisionTreeClassifier(random_state=1)\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "# model = GradientBoostingClassifier(random_state=1)\n",
    "# model = AdaBoostClassifier(random_state=1)\n",
    "# model = KNeighborsClassifier(random_state=1)\n",
    "# model = SVC(random_state=1)\n",
    "# model = GaussianNB(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50aa6054-dabf-4ce9-9bc1-1f7ead9f25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b2868b6-910f-4abd-9eae-bfc13d0b5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get preditions on test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508af0f-5b27-4cdf-9bb1-52181fb746e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save predictions as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "903ef958-c696-4f6a-a608-79187c4d9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions and actual values\n",
    "\n",
    "# Concatenate them into a single dataframe\n",
    "\n",
    "# Display output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834aac3-93d5-4232-9917-644195bd1450",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluate the model using performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b5bb193-6174-46e1-9528-4e81a1eb817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a confusion matrix\n",
    "\n",
    "# Display matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f07012e2-965a-4162-b5ca-01648a9f07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TP, FP, FN, TN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f003c-8656-4f82-8473-e9c761d454e2",
   "metadata": {},
   "source": [
    "**Accuracy**: \n",
    "\n",
    "This metric is calculated by dividing the correct predictions made by the total number of predictions made. In the context of our model, we are trying to answer the below questions:\n",
    "\n",
    "* In how many cases did we correctly predict that a customer is risk?\n",
    "* In how many cases did we correctly predict that a customer is not risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b44c4f1-180f-41d2-a13f-62fe7f226344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulate Accuracy Score\n",
    "\n",
    "# Display score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecabe9e-ec34-4211-a5fb-04ae19f6a3a2",
   "metadata": {},
   "source": [
    "**Precision**: \n",
    "\n",
    "This metric is calculated by dividing the correct positive predictions by the total number of positive predictions. In the context of our model, we are trying to answer - out of all the cases where we predicted that a customer is risk, how many customers are actually risk\n",
    "\n",
    "This metric comes from the prespective of checking how good we were when predicting the positive class, but only out of all the predictions we made for the positive class. In other words, \n",
    "\n",
    "* I am **concerned** about how many customers were actually identified as risk customers only out of the ones I predicted that were at-risk (the penalty is from predicting cases which were not actually at-risk, as being at-risk)\n",
    "* I am **not concerned** about the cases where I missed out on predicting that a customer is at-risk, when actually there was evidence of risk after duraion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04f87e11-29d2-43a1-81ff-e3a600d1af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision Score\n",
    "\n",
    "# Display score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0ed4b-dcb6-4d21-ae10-b327af1be2ef",
   "metadata": {},
   "source": [
    "**Recall**:\n",
    "\n",
    "This metric is calculated by dividing the correct positive predictions by the total number of actual positives. In the context of our model, we are trying to answer - out of all the cases where customers were actually risk, how many did I predict were at-risk?\n",
    "\n",
    "This metric comes from the prespective of checking how good we were with predicting the positive class, out of all the actual positive cases. In other words, \n",
    "\n",
    "* I am concerned about how many cases I was able to identify as at-risk out of all the customers who were risk (the penalty is from missing out on identifying a case as at-risk, when actually it was)\n",
    "* I am not concerened about the cases where I wrongly predicted that a customers was at-risk, when actually there was no risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a0072d6-54db-4859-9239-e890bb52b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recall Score\n",
    "\n",
    "# Display score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f1c29-dc1a-405f-aed5-a51756fae23e",
   "metadata": {},
   "source": [
    "**F1 score**:\n",
    "\n",
    "The F1 score is a metric that combines the merits of both precision and recall by calculating the harmonic mean between the two of them. In other words, this score is concerned with make sure \n",
    "\n",
    "* We don't wrongly lable a case as at-risk when it is not (which can lead to unnecessarily treating a customer)\n",
    "* We don't wrongly lable a case as not at-risk when it is (which can lead to missing out on treating a customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35608f07-4f7f-4028-b33a-18976b524ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1-score\n",
    "\n",
    "# Display score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68d1c2-fec6-451d-8b10-7c6bdaa0f8ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Tuning\n",
    "\n",
    "A model by default is built on set internal parameters, for example, in the Random Forest classifier, the `max_depth` value which tells how deep the tree must expand is set to `None` by default - which means the tree will expand until it finds all the pure leaves\n",
    "\n",
    "This will definitely work out well for the training data, but you would be over-fitting the model if you allow the depth to go as deep as \"stopping only when you find pure leaves\"! Here are some of the other significant questions you can ask:\n",
    "\n",
    "* What should be the minimum number of samples in a node to call it a leaf?\n",
    "* How do you score your features on their strength to predict?\n",
    "* What is the maximum number of leaf nodes? - too many leaves means you might be over-fitting\n",
    "\n",
    "When building an ML model, you can decide what these hidden parameters must be. For RandomForest Classifier, you can find all the hyper-parameters in this documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "**Hyper-parameter Tuning** is the art of figuring out what works best for your model - performing well statistically and aligning with your business context & needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686227d6-beda-4902-97a2-6e77fa725801",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define the parameter space & train the model\n",
    "\n",
    "Each model is build on a different algorithm, and hence the hyper-parameters may vary. So before you tune these models, refer to the below sklearn documentations to check the parameters and modify your tuning code accordingly\n",
    "\n",
    "* [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [sklearn.ensemble.GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "* [sklearn.ensemble.AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "* [sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* [sklearn.naive_bayes.GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb78b2e3-18c5-414b-8916-0320be6df5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameter space / grid to tune on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b1333d4-f0a2-43df-9c1d-218c455c1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for Grid Search Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b67a932-3132-43d8-a59b-ad39a26e49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate the model on all parameter combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "193c0adf-d608-4285-b521-524c7a0e0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results into the dataframe\n",
    "\n",
    "# Get the top 5 models which have the best mean_test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488aff2-39c7-4b3d-9fae-32dd507d3375",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Re-build the model & predict with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "010f34dc-7933-4487-9c8c-8fc3f3a587b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-build the model using the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75a3c865-2502-4e99-a1f2-867734d72273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the model using the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec34a4d3-f703-4f21-8c6e-5c39c605824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions and actual values\n",
    "\n",
    "# Concatenate them into a single dataframe\n",
    "\n",
    "# Display output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f1560-3165-48c6-8bd9-1f792c846f27",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluate the tuned model (compare performace with baseline model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fbf9ec7-7ca5-457e-bb0f-a5442fb3c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a confusion matrix\n",
    "\n",
    "# Display matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "245c7edb-a226-491b-a6e4-8c51ffe331d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TP, FP, FN, TN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "443ce465-a97d-4000-815b-b749bfc3e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulate all performance metrics - after tuning\n",
    "\n",
    "\n",
    "# Display performance metrics before & after tuning, and the % increment achieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e20b5-61f3-4068-91b4-44c43a43bd71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Deployment\n",
    "\n",
    "A model is deployed when it is \"fit for production use\" - but what does it really mean to \"deploy\" a model? All you are doing is packaging the model you trained as a python code so that it can be used by a stakeholder to input newly arriving data and receive predictions to take action within the business context\n",
    "\n",
    "This is known as creating an **Endpoint**. An endpoint is a system / node / computer / machince where your code lives, and can be triggered by giving inputs to get predictions out\n",
    "\n",
    "NOTE: _Before we create docker containers and deploy our model, let's first learn how to deploy it locally and see how it works_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d4685-9d6b-428d-af53-7d8b1152f824",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Understanding how \"argument parsing\" works\n",
    "\n",
    "You model code has to be flexible to take in different hyper-parameter inputs and new production data in the future. So you need a way to input values into your code before it starts running as it is unproductive for you to change multiple values in your code one at a time when needed. You can make sure your code is parameterized using the `argparse` library. Let's learn how to do this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cdca5283-99af-4571-96fe-ed8c7f146d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing argparse_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile argparse_example.py\n",
    "\n",
    "# Package to parse arguments\n",
    "import argparse\n",
    "\n",
    "# Create a parser instance\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Set rules to parse variables\n",
    "parser.add_argument(\"--hyp-par-1\", type=int, default=10)\n",
    "parser.add_argument(\"--hyp-par-2\", type=int, default=5)\n",
    "parser.add_argument(\"--hyp-par-3\", type=int, default=200)\n",
    "\n",
    "# Read all input values into a variable\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Save each input value into separate variables\n",
    "hyperparam_1 = args.hyp_par_1\n",
    "hyperparam_2 = args.hyp_par_2\n",
    "hyperparam_3 = args.hyp_par_3\n",
    "\n",
    "# Display values\n",
    "print(\"training model with below hyper-parameters...:\")\n",
    "print(\"hyper-parameter-1: {}\".format(hyperparam_1))\n",
    "print(\"hyper-parameter-2: {}\".format(hyperparam_2))\n",
    "print(\"hyper-parameter-3: {}\".format(hyperparam_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6ff02-388b-46e7-b7d9-c1e0612f90cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modifying our model code before local deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c0ae0b0-9423-41ac-aa3c-33f7a4e8db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_script_local.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_script_local.py\n",
    "\n",
    "# ------------------------------\n",
    "# Import all necessary libraries\n",
    "# ------------------------------\n",
    "\n",
    "# Package to take in features and hyper-parameters are inputs\n",
    "\n",
    "\n",
    "# Packages to interact with system\n",
    "\n",
    "# Packages to process data\n",
    "\n",
    "\n",
    "# Packages to interact with AWS Services & Sagemaker\n",
    "\n",
    "\n",
    "# Packages for Machine Learning\n",
    "\n",
    "\n",
    "# Packages for Hyper-parameter tuning\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Parse test data & hyper-parameters\n",
    "# ----------------------------------\n",
    "\n",
    "# -----------------------\n",
    "# Setup sagemaker session\n",
    "# -----------------------\n",
    "\n",
    "# Setting up a sagemaker session\n",
    "\n",
    "\n",
    "# Get region and bucket\n",
    "\n",
    "\n",
    "# Display region and bucket\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Read the data & pre-process\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "# Read data from S3 into a pandas dataframe\n",
    "\n",
    "\n",
    "# Display the dataset\n",
    "\n",
    "# Split data into Train & Test dataframes\n",
    "\n",
    "\n",
    "# Write the train and test dataframes to sagemaker file browser\n",
    "\n",
    "# Upload train data to s3\n",
    "\n",
    "# Upload test data to s3\n",
    "\n",
    "\n",
    "# Display train and test data location in s3\n",
    "# print(trainpath)\n",
    "# print(testpath)\n",
    "\n",
    "# --------------------------\n",
    "# Build classification model\n",
    "# --------------------------\n",
    "\n",
    "# Read training & testing datasets from s3\n",
    "\n",
    "# Create train dataframes with features & target\n",
    "\n",
    "# Create test dataframes with features & target\n",
    "\n",
    "# Build model using the best parameters\n",
    "\n",
    "# Fit model\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Predict using the model\n",
    "# -----------------------\n",
    "\n",
    "# Save the predictions and actual values\n",
    "\n",
    "\n",
    "# Concatenate them into a single dataframe\n",
    "\n",
    "\n",
    "# Display output\n",
    "\n",
    "# --------------------\n",
    "# Evaluate Performnace\n",
    "# --------------------\n",
    "\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "\n",
    "# Display matrix\n",
    "\n",
    "\n",
    "# Calculate TP, FP, FN, TN\n",
    "\n",
    "\n",
    "# Calulate all performance metrics - after tuning\n",
    "\n",
    "\n",
    "# Display performance metrics before & after tuning, and the % increment achieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238180a-1e91-49ac-b080-bc76eaa6e865",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running Training, Hyper-parameter Tuning Jobs and Deploying the model on Docker\n",
    "\n",
    "Now that we have done training, tuning and deploying on our sagemaker local notebook, let's learn how to run these stages in the ML Lifecycle as processing jobs on Docker Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97764568-8b97-4b4e-930a-a9d2d3d6be45",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Prepare the model script to run on Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "850bebda-f519-4be8-aee5-b5f30c406d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_script_docker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_script_docker.py\n",
    "\n",
    "# ------------------------------\n",
    "# Import all necessary libraries\n",
    "# ------------------------------\n",
    "\n",
    "# Package to take in features and hyper-parameters are inputs\n",
    "\n",
    "\n",
    "# Packages to interact with system\n",
    "\n",
    "\n",
    "# Packages to process data\n",
    "\n",
    "\n",
    "# Packages for Machine Learning\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Function to persist model package\n",
    "# ---------------------------------\n",
    "\n",
    "# Write a  function will be used by the training model to create the model package\n",
    "# Use this as it is\n",
    "\n",
    "# Main code\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Parse test data & hyper-parameters\n",
    "    # ----------------------------------\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # test and train file\n",
    "    parser.add_argument(\"--test-file\", type=str, default='test.csv')\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    # hyper-parameters\n",
    "    parser.add_argument(\" \", type=str, default=\"gini\")\n",
    "    parser.add_argument(\" \", type=int, default=5)\n",
    "    parser.add_argument(\" \", type=int, default=50)\n",
    "    # docker contrainer default locations\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\")) #*\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\")) #*\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\")) #*\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # --------------------------\n",
    "    # Build classification model\n",
    "    # --------------------------\n",
    "\n",
    "    # Read training & testing datasets from s3\n",
    "    \n",
    "    # Create train dataframes with features & target\n",
    "\n",
    "    # Create test dataframes with features & target\n",
    " \n",
    "\n",
    "    # Build model using the best parameters\n",
    "\n",
    "\n",
    "    # Fit model\n",
    "\n",
    "\n",
    "    # -----------------------\n",
    "    # Predict using the model\n",
    "    # -----------------------\n",
    "\n",
    "    # Save the predictions and actual values\n",
    "\n",
    "\n",
    "    # Concatenate them into a single dataframe\n",
    "\n",
    "    # Display output\n",
    "    \n",
    "\n",
    "    # --------------------\n",
    "    # Evaluate Performnace\n",
    "    # --------------------\n",
    "\n",
    "\n",
    "    # Evaluate the model using a confusion matrix\n",
    "\n",
    "    # Display matrix\n",
    "\n",
    "    # Calculate TP, FP, FN, TN\n",
    "\n",
    "    # Calulate all performance metrics - after tuning\n",
    "\n",
    "    # Display performance metrics before & after tuning, and the % increment achieved\n",
    "\n",
    "\n",
    "    # ------------------------\n",
    "    # Save model package file\n",
    "    # ------------------------\n",
    "\n",
    "    # persist model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddfb561-d3f9-4dfe-9ccd-04deb3bd7032",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train the model using SageMaker Estimator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "931defd7-b292-4917-b705-2e78ed508067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to train model\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Set framework version (stable)\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "# Creat the sklearn estimator instance\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\" \", # your model code\n",
    "    role=get_execution_role(), # the default IAM role used\n",
    "    instance_count=1, # number of nodes\n",
    "    instance_type=\" \", # EC2 instance type\n",
    "    framework_version=FRAMEWORK_VERSION, # Framework version\n",
    "    base_job_name=\" \", # Prefix of the job name\n",
    "    hyperparameters={ # Hyper-parameters\n",
    "      \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "245f9c45-5683-4f5d-92cf-865edeb885ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Training Job\n",
    "#sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c830c20-969a-4dff-aa8c-a0ace95aca6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tune the model using SageMaker Tuner Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "445a9673-ddd0-492a-aa5a-0f9ae5f60fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library to tune models\n",
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    \n",
    "}\n",
    "\n",
    "# Create an optimizer instance\n",
    "sklearn_optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=sklearn_estimator, # model training instance\n",
    "    hyperparameter_ranges=hyperparameter_ranges, # parameter space\n",
    "    base_tuning_job_name=\" \", # Prefix of the tuning job\n",
    "    objective_type=\" \", \n",
    "    objective_metric_name=\" \",\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=5,\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy:([0-9.]+).*$\"} # search logs on cloudwatch\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d1f6640-96b8-461d-8d3e-210f42067264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_optimizer.fit({\"train\": trainpath, \"test\": testpath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da6e35bc-defa-4c4a-a2d1-5b68a703df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tuner results in a df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c092e1-5b1b-491e-bc27-dba49de844e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Deploy the model using SageMaker Model Deploy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92944799-3fa2-4aed-9799-a219ba1d6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model artefact into a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0493b068-94de-4734-829e-78436bc7cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to deploy model\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=artifact, # The model zip file the training job generated\n",
    "    role=get_execution_role(), # Default IAM role\n",
    "    entry_point=\" \", # Model Code\n",
    "    framework_version=FRAMEWORK_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7143bd6-f374-4621-9e16-8622d5155a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy SKLearn Predictor\n",
    "sklearn_predictor = model.deploy(instance_type=\" \", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fcd2927-65d4-4381-9594-5e846ec18c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test data using deployed model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fc501e1-4c3b-4e69-9b55-15c9028fb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as output dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4e10b48-fd6f-404d-94f2-0c5f85bc3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using a confusion matrix\n",
    "\n",
    "# Display matrix\n",
    "# print(matrix)\n",
    "\n",
    "# Calculate TP, FP, FN, TN\n",
    "\n",
    "# Calulate all performance metrics - after tuning\n",
    "\n",
    "\n",
    "# Display performance metrics before & after tuning, and the % increment achieved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c4d74-bfa9-4d00-a7ce-d1b4e65e3821",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Delete the Endpoint\n",
    "\n",
    "**Important!** An Endpoint is a LIVE node which is always running, ready to process & predict to give you output. So unless you are making real-time predictions on streaming data, delete your endpoints after use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ead4433-2b8c-4f9c-bbe6-505bfcb217d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure your end-point should be deleted in order to avoid charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e54a44a3-5531-4749-b1b1-968ad450b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3.delete_endpoint(EndpointName=sklearn_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14784d24-4659-4c4b-a133-740f33efa538",
   "metadata": {},
   "source": [
    "# Thank you"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
